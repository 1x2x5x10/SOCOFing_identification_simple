{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "socofing_simple.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm-ORCu21h8P"
      },
      "source": [
        "# -1) SAVE / RESUME / LOAD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGGLJkWK1hld"
      },
      "source": [
        "SAVE = True # NAME = ?\n",
        "#---\n",
        "RESUME = True # TIMESTAMP = ?\n",
        "TIMESTAMP = \"\"\n",
        "#---\n",
        "LOAD_now = False\n",
        "LOAD_past = True\n",
        "LOAD = LOAD_now or LOAD_past"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn9DXM4dXLnj"
      },
      "source": [
        "# 0) Drive mount & Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiYdQRdGWVKK"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAd6Ns2HWfgu"
      },
      "source": [
        "# cd \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpb0imRBWhlF"
      },
      "source": [
        "!pwd\n",
        "!ls -l | grep ^- | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuLEVWTkIVBN"
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from glob import glob\n",
        "import time\n",
        "import datetime\n",
        "from pytz import timezone\n",
        "import sys\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3VRexhdWyhr"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "# import cv2\n",
        "import PIL\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJvMMqLFXWzS"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "#---\n",
        "import torchvision\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "#---\n",
        "from tqdm import tqdm # , trange"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-UaxHWOI99N"
      },
      "source": [
        "# 1) Environment setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7iREERVIm7X"
      },
      "source": [
        "current_dir = os.getcwd(); print(current_dir)\n",
        "raw_data_dir = current_dir + \"/raw_data\"\n",
        "result_dir = current_dir + \"/result\"\n",
        "#for loc in [result_dir]: \n",
        "#     if not os.path.exists(loc): os.makedirs(loc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3rxJK26HaZC"
      },
      "source": [
        "# True: GPU is avaliable / False: GPU is unavailable\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "# if USE_CUDA is TRUE: use GPU / else: use CPU\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\"); print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NJPhweGPdIw"
      },
      "source": [
        "print(\"Python:\", sys.version)\n",
        "print(\"PyTorch:\", torch.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRIwaB1FSIIU"
      },
      "source": [
        "pd.set_option(\"max_colwidth\", 100)\n",
        "# pd.reset_option(\"max_colwidth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qes-nqArKUTe"
      },
      "source": [
        "# 2) Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IElFxTp7A_Nz"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-tY_8Pk_qn4"
      },
      "source": [
        "col_names = [\"BMP\", \"Alt\", \"Diff\", \"Type\", \"Num\", \"Gender\", \"Hand\", \"Finger\"]\n",
        "data_category = {\"All\"       : {\"color\": \"RGB\", \"addr_tail\": \"/SOCOFING\"},\n",
        "                 \"Alt\"       : {\"color\": \"grayscale\", \"addr_tail\": \"/SOCOFING/Altered\"},\n",
        "                 \"Real_rgb\"  : {\"color\": \"RGB\", \"addr_tail\": \"/SOCOFING/Real\"},\n",
        "                 \"Real_gray\" : {\"color\": \"grayscale\", \"addr_tail\": \"/SOCOFING/Real\"}\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuTEkxew_xDH"
      },
      "source": [
        "Real"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqB8hWcL_quZ"
      },
      "source": [
        "##### Real #####\n",
        "start_time = time.time()\n",
        "#---\n",
        "Real_data_Path = Path(\"./raw_data/SOCOFING/Real/Real\")\n",
        "Real_BMP_Path = sorted(Real_data_Path.glob(\"*.BMP\")) # r\"*/*.BMP\"\n",
        "print(len(Real_BMP_Path))\n",
        "#---\n",
        "Real_Series = { name: [] for name in col_names}\n",
        "#---\n",
        "Real_Series[\"BMP\"] = pd.Series(Real_BMP_Path, name = \"BMP\").astype(str)\n",
        "#---\n",
        "Real_name = list(map(lambda x: os.path.split(x)[1], Real_BMP_Path))\n",
        "Real_Series[\"Num\"] = pd.Series(list(map(lambda x: x.split(\"__\")[0], Real_name)), name = \"Num\")\n",
        "Real_info = list(map(lambda x: x.split(\"__\")[1].split(\"_\"), Real_name))\n",
        "Real_Series[\"Gender\"] = pd.Series(list(map(lambda x: x[0], Real_info)), name = \"Gender\")\n",
        "Real_Series[\"Hand\"] = pd.Series(list(map(lambda x: x[1], Real_info)), name = \"Hand\")\n",
        "Real_Series[\"Finger\"] = pd.Series(list(map(lambda x: x[2], Real_info)), name = \"Finger\")\n",
        "#---\n",
        "Real_Series[\"Alt\"] = pd.Series([\"No\" for i in range(len(Real_BMP_Path))], name = \"Alt\")\n",
        "Real_Series[\"Diff\"] = pd.Series([\"No\" for i in range(len(Real_BMP_Path))], name = \"Diff\")\n",
        "Real_Series[\"Type\"] = pd.Series([\"No\" for i in range(len(Real_BMP_Path))], name = \"Type\")\n",
        "#---\n",
        "concat_list = [Real_Series[col] for col in col_names]\n",
        "Real_Data = pd.concat(concat_list, axis=1)\n",
        "print(time.time()-start_time, \"sec\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B3XpYja_qyJ"
      },
      "source": [
        "print(Real_Data.isnull().values.any()) # print(Real_Data.isna().sum())\n",
        "Real_Data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVJ29ZbV_q1f"
      },
      "source": [
        "# 600 users / 1 user = 10 fingers\n",
        "count = Real_Data.groupby('Num')['Num'].count()\n",
        "# print(count)\n",
        "print(len(count))\n",
        "for i in count:\n",
        "    if i == 10: pass\n",
        "    else: print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na-pM_if_yy3"
      },
      "source": [
        "Altered"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4gzDlzQ_q5b"
      },
      "source": [
        "##### Altered #####\n",
        "start_time = time.time()\n",
        "#---\n",
        "Alt_data_Path = Path(\"./raw_data/SOCOFING/Altered\")\n",
        "Alt_BMP_Path = sorted(Alt_data_Path.glob(r\"*/*.BMP\")) # r\"*/*.BMP\"\n",
        "print(len(Alt_BMP_Path))\n",
        "#---\n",
        "Alt_Series = { name: [] for name in col_names}\n",
        "#---\n",
        "Alt_Series[\"BMP\"] = pd.Series(Alt_BMP_Path, name = \"BMP\").astype(str)\n",
        "#---\n",
        "Alt_name = list(map(lambda x: os.path.split(x)[1], Alt_BMP_Path))\n",
        "Alt_Series[\"Num\"] = pd.Series(list(map(lambda x: x.split(\"__\")[0], Alt_name)), name = \"Num\")\n",
        "Alt_info = list(map(lambda x: x.split(\"__\")[1].split(\"_\"), Alt_name))\n",
        "Alt_Series[\"Gender\"] = pd.Series(list(map(lambda x: x[0], Alt_info)), name = \"Gender\")\n",
        "Alt_Series[\"Hand\"] = pd.Series(list(map(lambda x: x[1], Alt_info)), name = \"Hand\")\n",
        "Alt_Series[\"Finger\"] = pd.Series(list(map(lambda x: x[2], Alt_info)), name = \"Finger\")\n",
        "#---\n",
        "Diff_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1].split(\"-\")[1], Alt_BMP_Path))\n",
        "for difficulty in [\"Easy\", \"Medium\", \"Hard\"]:\n",
        "    print(\"Altered-\" + difficulty, \":\", Diff_Labels.count(difficulty))\n",
        "#---\n",
        "Alt_Series[\"Alt\"] = pd.Series([\"Yes\" for i in range(len(Alt_BMP_Path))], name = \"Alt\")\n",
        "Alt_Series[\"Diff\"] = pd.Series(Diff_Labels, name = \"Diff\")\n",
        "Alt_Series[\"Type\"] = pd.Series(list(map(lambda x: x[4].split(\".\")[0], Alt_info)), name = \"Type\")\n",
        "#---\n",
        "concat_list = [Alt_Series[col] for col in col_names]\n",
        "Alt_Data = pd.concat(concat_list, axis=1)\n",
        "print(time.time()-start_time, \"sec\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FixOrcK_1rg"
      },
      "source": [
        "print(Alt_Data.isnull().values.any()) # print(Alt_Data.isna().sum())\n",
        "Alt_Data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LReDaj4_1t-"
      },
      "source": [
        "count = Alt_Data.groupby(['Num', 'Diff'])['Num'].count()\n",
        "print(len(count))\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D_4U_MF_3ev"
      },
      "source": [
        "## Dataset (using torchvision)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KbE9PWOrjUR"
      },
      "source": [
        "batch_size = 128\n",
        "# num_workers = 1 # number of CPU (or GPU)\n",
        "# n_iters = 1000\n",
        "# num_epochs = n_iters / (len(features_train) / batch_size)\n",
        "# num_epochs = int(num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhwocNhFSNpm"
      },
      "source": [
        "trans = {\"RGB\": 0, \"grayscale\": 0}\n",
        "pixel = 128\n",
        "trans[\"RGB\"] = transforms.Compose([#transforms.Grayscale(num_output_channels=1),\n",
        "                                   transforms.Resize((pixel, pixel)),\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                   ])\n",
        "trans[\"grayscale\"] = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
        "                                   transforms.Resize((pixel, pixel)),\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize(0.5, 0.5)\n",
        "                                   ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcT1XaROj8ar"
      },
      "source": [
        "LABELS_UNIQUE = []\n",
        "for person in list(map(lambda x: str(x), range(1, 600 + 1))):\n",
        "    for hand in [\"Right\", \"Left\"]:\n",
        "        for finger in [\"thumb\", \"index\", \"middle\", \"ring\", \"little\"]:\n",
        "            LABELS_UNIQUE.append(\"_\".join([person, hand, finger]))\n",
        "print(LABELS_UNIQUE[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPUBhoO4OfFY"
      },
      "source": [
        "class SOCOFING_Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root_dir, transforms=None, label=None, color=\"RGB\", labels_unique = LABELS_UNIQUE):\n",
        "        self.root_dir = root_dir\n",
        "        self.classes = os.listdir(self.root_dir)\n",
        "        self.transforms = transforms\n",
        "        self.color = color\n",
        "        #---\n",
        "        self.class_data = {cls: [] for cls in self.classes}\n",
        "        self.col_names = [\"BMP\", \"Alt\", \"Diff\", \"Type\", \"Num\", \"Gender\", \"Hand\", \"Finger\"]\n",
        "        self.class_Series = {cls : {col: [] for col in self.col_names} for cls in self.classes}\n",
        "        self.class_df = {cls: 0 for cls in self.classes}\n",
        "        #---\n",
        "        self.label_name = label\n",
        "        self.labels = []\n",
        "        self.labels_unique = labels_unique\n",
        "        self.data = []\n",
        "        self.DataFrame = 0\n",
        "        \n",
        "        for idx, cls in enumerate(self.classes):\n",
        "            cls_dir = os.path.join(self.root_dir, cls)\n",
        "            self.class_data[cls] = glob(os.path.join(cls_dir, '*.BMP')) # list\n",
        "            # print(cls, len(self.class_data[cls]))\n",
        "            if len(self.class_data[cls]) == 0:\n",
        "                self.class_data[cls] = glob(os.path.join(cls_dir, r'*/*.BMP'))        \n",
        "            #---\n",
        "            ADDR = list(map(lambda x: x.split(\"/\")[-3:], self.class_data[cls]))\n",
        "            self.class_Series[cls][\"BMP\"] = pd.Series(list(map(lambda x: \"/\".join(x), ADDR)), name = \"BMP\")\n",
        "            self.class_Series[cls][\"Alt\"] = pd.Series(list(map(lambda x: x[0], ADDR)), name = \"Alt\")\n",
        "            self.class_Series[cls][\"Diff\"] = pd.Series(list(map(lambda x: x[1], ADDR)), name = \"Diff\")\n",
        "            self.class_Series[cls][\"Diff\"] = self.class_Series[cls][\"Diff\"].replace({\"Altered-Easy\": \"Easy\", \"Altered-Hard\": \"Hard\", \"Altered-Medium\": \"Medium\"}) # Real: Real / Altered: Easy, Hard, Medium\n",
        "            #---\n",
        "            NAME = list(map(lambda x: x[2], ADDR))\n",
        "            self.class_Series[cls][\"Num\"] = pd.Series(list(map(lambda x: x.split(\"__\")[0], NAME)), name = \"Num\")\n",
        "            #---\n",
        "            NAME= list(map(lambda x: x.split(\"__\")[1].split(\"_\"), NAME))\n",
        "            self.class_Series[cls][\"Gender\"] = pd.Series(list(map(lambda x: x[0], NAME)), name = \"Gender\")\n",
        "            self.class_Series[cls][\"Hand\"] = pd.Series(list(map(lambda x: x[1], NAME)), name = \"Hand\")\n",
        "            self.class_Series[cls][\"Finger\"] = pd.Series(list(map(lambda x: x[2], NAME)), name = \"Finger\")\n",
        "            self.class_Series[cls][\"Type\"] = pd.Series(list(map(lambda x: x[-1].split(\".\")[0], NAME)), name = \"Type\")\n",
        "            self.class_Series[cls][\"Type\"] = self.class_Series[cls][\"Type\"].replace({\"finger\": \"Real\"}) # Real: Real / Altered: Obl, Zcut, C\n",
        "            #---\n",
        "            concat_list = [self.class_Series[cls][col] for col in col_names]\n",
        "            self.class_df[cls] = pd.concat(concat_list, axis=1)\n",
        "            #--\n",
        "            if self.label_name == None:\n",
        "                self.class_df[cls]['Label'] = self.class_df[cls][\"Alt\"]\n",
        "            else:\n",
        "                self.class_df[cls]['Label'] = self.class_df[cls][self.label_name].agg('_'.join, axis=1)\n",
        "            # end of for loop\n",
        "        #---\n",
        "        for cls in self.classes:\n",
        "            self.data = self.data + self.class_data[cls]\n",
        "        #---\n",
        "        concat_list = [self.class_df[cls] for cls in self.classes]\n",
        "        self.DataFrame = pd.concat(concat_list, axis = 0,  ignore_index = True)\n",
        "        #---\n",
        "        self.labels = list(self.DataFrame['Label'])\n",
        "        #self.labels_unique = list(set(self.labels))\n",
        "        #start_time = time.time()\n",
        "        self.labels = list(map(lambda x: self.labels_unique.index(x), self.labels ))\n",
        "        #print(\"labels:\", time.time()-start_time, \"sec\")\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.data[idx], self.labels[idx]\n",
        "        if self.color == \"grayscale\":\n",
        "            img = PIL.Image.open(img_path).convert('L')\n",
        "        else:\n",
        "            img = PIL.Image.open(img_path).convert('RGB')\n",
        "        if self.transforms:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        info_dict = {col: self.DataFrame[col][idx] for col in col_names}\n",
        "        #output = {'image':img, 'label':label, 'info':info_dict}\n",
        "        output = (img, label) #, info_dict)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A36kGxWPADvH"
      },
      "source": [
        "label_list = [\"Num\", \"Hand\", \"Finger\"]\n",
        "FING_dsets = {}\n",
        "for cat in data_category.keys(): \n",
        "    color = data_category[cat][\"color\"]\n",
        "    tail = data_category[cat][\"addr_tail\"]\n",
        "    root_dir = raw_data_dir + tail\n",
        "\n",
        "    FING_dsets[cat] = SOCOFING_Dataset(root_dir = root_dir, transforms = trans[color], label = label_list, color = color, labels_unique = LABELS_UNIQUE)\n",
        "    print(cat, len(FING_dsets[cat]), end=\" / \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLh2KdliJLDf"
      },
      "source": [
        "check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdXyQAJsJLx5"
      },
      "source": [
        "# check 1\n",
        "FING_dsets[\"All\"].DataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm6xpMJWhkN4"
      },
      "source": [
        "# check 2\n",
        "FING_dsets[\"Alt\"].__getitem__(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iofpl41L0VzK"
      },
      "source": [
        "# check 3\n",
        "FING_dsets[\"Real_rgb\"].__getitem__(11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s39ArkrgnEuQ"
      },
      "source": [
        "# check 3\n",
        "FING_dsets[\"Real_gray\"].__getitem__(11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2VwI7vwJShp"
      },
      "source": [
        "## Visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBPtTHBOAAqZ"
      },
      "source": [
        "def imshow(img):\n",
        "    img = img/2 + 0.5 #unnormalize\n",
        "    np_img = img.numpy()\n",
        "    plt.imshow(np.transpose(np_img, (1,2,0)))\n",
        "    #print(np_img.shape)\n",
        "    #print((np.transpose(np_img, (1,2,0))).shape)\n",
        "\n",
        "def imshow_one(addr):\n",
        "    plt.figure(figsize=(2,2))\n",
        "    img_name = raw_data_dir +\"/SOCOFING/\" + addr\n",
        "    img = PIL.Image.open(img_name).convert(\"L\")\n",
        "    arr = np.asarray(img)\n",
        "    #print(arr.shape)\n",
        "    plt.title(addr)\n",
        "    plt.imshow(arr, cmap='gray', vmin=0, vmax=255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-3PlDlLDLjp"
      },
      "source": [
        "FING_dataloader = {}\n",
        "for i in data_category:\n",
        "    FING_dataloader[i] = DataLoader(FING_dsets[i], batch_size = batch_size, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUgcpwAKAAoa"
      },
      "source": [
        "TEMP = \"Real_gray\"\n",
        "dataloader = FING_dataloader[TEMP]\n",
        "dataiter = iter(dataloader)\n",
        "outputs = dataiter.next() # output = {'image':img, 'label':label, 'info':info_dict}\n",
        "images, labels = outputs[0], outputs[1]\n",
        "print(labels, \"\\n---\")\n",
        "#---\n",
        "print(images.shape)\n",
        "imshow(torchvision.utils.make_grid(images, nrow=8))\n",
        "print(\"---\")\n",
        "#---\n",
        "imshow_one(FING_dsets[TEMP].DataFrame[\"BMP\"][0])\n",
        "imshow_one(FING_dsets[TEMP].DataFrame[\"BMP\"][1])\n",
        "#imshow_one(FING_dsets[TEMP].DataFrame[\"BMP\"][2])\n",
        "#imshow_one(FING_dsets[TEMP].DataFrame[\"BMP\"][3])\n",
        "# it seems there is no problem"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFwwBWALQPBl"
      },
      "source": [
        "# 3) Split into Train / Validation / Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZuHBbqOQoo8"
      },
      "source": [
        "##### seed #####\n",
        "random.seed(1234)\n",
        "np.random.seed(1234)\n",
        "torch.manual_seed(1234)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLL-QWT6AAmP"
      },
      "source": [
        "Train_Set = {}\n",
        "Validation_Set = {}\n",
        "Test_Set = {}\n",
        "for cat in data_category:\n",
        "    num = len(FING_dsets[cat])\n",
        "    train_size = int(0.6 * num)\n",
        "    validation_size = int(0.2 * num)\n",
        "    test_size = num - train_size - validation_size\n",
        "    random.seed(1234)\n",
        "    np.random.seed(1234)\n",
        "    torch.manual_seed(1234)\n",
        "    if device == 'cuda':\n",
        "        torch.cuda.manual_seed_all(1234)\n",
        "    Train_Set[cat], Validation_Set[cat], Test_Set[cat] = torch.utils.data.random_split(FING_dsets[cat], [train_size, validation_size, test_size], generator=torch.Generator().manual_seed(1234))\n",
        "    print(cat, train_size, validation_size, test_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WUngzg5AAkI"
      },
      "source": [
        "for cat in data_category:\n",
        "    lbl = Train_Set[cat][0][1]\n",
        "    print(cat, \":\", lbl, \"=\", FING_dsets[cat].labels_unique[lbl], end =\" / \")\n",
        "    print(\"unique:\", len(FING_dsets[cat].labels_unique))\n",
        "# (Perhaps..) All : 4154 = 416_Right_little / Alt : 3893 = 390_Right_ring / Real_rgb : 1378 = 138_Left_ring / Real_gray : 1378 = 138_Left_ring"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgQOiAgAzxay"
      },
      "source": [
        "Train_loader = {}\n",
        "Validation_loader = {}\n",
        "Test_loader = {}\n",
        "for cat in data_category:\n",
        "    Train_loader[cat] = DataLoader(Train_Set[cat], batch_size = batch_size, shuffle = False)\n",
        "    Validation_loader[cat] = DataLoader(Validation_Set[cat], batch_size = batch_size, shuffle = False)\n",
        "    Test_loader[cat] = DataLoader(Test_Set[cat], batch_size = batch_size, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fICkSvhlue8y"
      },
      "source": [
        "# 4) Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5zxtm8fD34P"
      },
      "source": [
        "all_models = [\"TypicalCNN\"]\n",
        "model_dict = { m: 0 for m in all_models}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt0M7KfPsjUJ"
      },
      "source": [
        "## 4.1) TypicalCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMnLcS-h3WCY"
      },
      "source": [
        "class TypicalCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TypicalCNN, self).__init__()\n",
        "        # 1 input image channel, 16 output channels, 3x3 square convolution kernel\n",
        "        self.conv1 = nn.Conv2d(1,  16, kernel_size=3, stride=2, padding=1) \n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout2d(0.4)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 2048)\n",
        "        self.fc2 = nn.Linear(2048, 1024)\n",
        "        self.fc3 = nn.Linear(1024, 6000)\n",
        "        \n",
        "    def forward(self, x): # 128\n",
        "        check = False\n",
        "        if check: print(0, x.shape)\n",
        "        x = self.batchnorm1(F.relu(self.conv1(x))) # 64\n",
        "        if check: print(1, x.shape)\n",
        "        x = self.batchnorm2(F.relu(self.conv2(x))) # 32\n",
        "        if check: print(2, x.shape)\n",
        "        x = self.dropout(self.batchnorm2(self.pool(x))) # 16\n",
        "        if check: print(3, x.shape)\n",
        "        x = self.batchnorm3(self.pool(F.relu(self.conv3(x)))) # 8\n",
        "        if check: print(4, x.shape)\n",
        "        x = self.dropout(self.conv4(x)) # 8\n",
        "        if check: print(5, x.shape)\n",
        "        x = x.view(-1, 64 * 8 * 8) # Flatten layer\n",
        "        if check: print(6, x.shape)\n",
        "        x = self.dropout(self.fc1(x))\n",
        "        if check: print(7, x.shape)\n",
        "        x = self.dropout(self.fc2(x))\n",
        "        if check: print(8, x.shape)\n",
        "        x = F.log_softmax(self.fc3(x), dim = 1)\n",
        "        if check: print(9, x.shape)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSG8VQq92guU"
      },
      "source": [
        "Set model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbwkA1wV4utc"
      },
      "source": [
        "if device == \"cpu\":\n",
        "    model = TypicalCNN() \n",
        "else:\n",
        "    model =  TypicalCNN().to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8CuwW2Z2cZk"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ7Ux_172k2d"
      },
      "source": [
        "Choose data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziwv1R0G5G76"
      },
      "source": [
        "DATA_cat = \"Alt\"\n",
        "n_epochs = 30\n",
        "# print_every = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KobyHh2w2Whd"
      },
      "source": [
        "train_loader = Train_loader[DATA_cat]\n",
        "validation_loader = Validation_loader[DATA_cat]\n",
        "test_loader = Test_loader[DATA_cat]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH5qW5zY2n39"
      },
      "source": [
        "Training preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXl6uk1L6MJN"
      },
      "source": [
        "valid_loss_min = np.Inf\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "total_step = len(train_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXsRgGZVKgcy"
      },
      "source": [
        "Save or not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TvxB2QVNDSG"
      },
      "source": [
        "##### SAVE or not #####\n",
        "NAME = \"model_TypicalCnn\"\n",
        "#---\n",
        "now_utc = datetime.datetime.now(timezone(\"UTC\")); now_kst = now_utc.astimezone(timezone(\"Asia/Seoul\")); print(now_kst)\n",
        "nowDatetime = now_kst.strftime('%Y_%m_%d_%Hh%Mm%Ss'); print(nowDatetime)\n",
        "if SAVE == True:\n",
        "    saving_dir = result_dir + \"/classify/\" + nowDatetime\n",
        "    for loc in [saving_dir]: \n",
        "        if not os.path.exists(loc): os.makedirs(loc)\n",
        "    TXT_PATH = saving_dir + \"/model_updated_epoch.txt\"\n",
        "    f = open(TXT_PATH, 'w')\n",
        "    f.write(\"#\"+ nowDatetime +\"\\n-----\\n\")\n",
        "    f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvCmuuBsKh6J"
      },
      "source": [
        "Resume or not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK-YIKKauYbV"
      },
      "source": [
        "##### RESUME or new #####\n",
        "DICT_PATH_now = saving_dir + \"/Cell_info.json\"\n",
        "DICT_PATH_past = result_dir + \"/classify/\" + TIMESTAMP +\"/Cell_info.json\"\n",
        "# define Cell_info (dictionary)\n",
        "Cell_info = {\"time\": nowDatetime, \"epoch_past\": 0, \"best val.acc\": -1, \"best epoch\": -1, \"best val.loss\": -1}\n",
        "if RESUME == True: # SAVE == True\n",
        "    json_file = open(DICT_PATH_past, \"r\")\n",
        "    Cell_info = json.load(json_file)\n",
        "else:\n",
        "    pass\n",
        "print(Cell_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHI0FRgJKfPa"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JC8tzha3V99"
      },
      "source": [
        "##### Training #####\n",
        "# Resume in current session or Not\n",
        "if RESUME == True:\n",
        "    if os.path.exists(DICT_PATH_now):\n",
        "        json_file = open(DICT_PATH_now, \"r\")\n",
        "        Cell_info = json.load(json_file)\n",
        "else:\n",
        "    pass\n",
        "print(Cell_info)\n",
        "#--- \n",
        "time.sleep(0.3)\n",
        "start_time = {\"epoch\": 0, \"loader\":0, \"model\": 0}\n",
        "#---\n",
        "for epoch in range(1 + Cell_info[\"epoch_past\"], n_epochs + 1 + Cell_info[\"epoch_past\"]):\n",
        "    model.train()\n",
        "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
        "        running_loss = 0.0\n",
        "        # scheduler.step(epoch)\n",
        "        correct = 0\n",
        "        total=0\n",
        "        # print(f'Epoch {epoch}\\n')\n",
        "        for data_, target_ in tepoch:\n",
        "            tepoch.set_description(f\"Epoch {epoch}\")\n",
        "        # for batch_idx, (data_, target_) in enumerate(train_loader):\n",
        "            if device != \"cpu\": data_, target_ = data_.to(device), target_.to(device) # on GPU\n",
        "            #-- zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            #-- forward + backward + optimize\n",
        "            outputs = model(data_)\n",
        "            loss = criterion(outputs, target_)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            #-- print statistics\n",
        "            _, pred = torch.max(outputs, dim=1)\n",
        "            loss_now = loss.item()\n",
        "            correct_now = (pred == target_).sum().item()\n",
        "            accuracy_now = correct_now / batch_size\n",
        "            #--\n",
        "            running_loss += loss_now\n",
        "            correct += correct_now\n",
        "            total += target_.size(0) # same as += batch_size\n",
        "            #--\n",
        "            tepoch.set_postfix(loss = loss.item(), accuracy =100. * accuracy_now, position = epoch - 1) #; time.sleep(0.1)\n",
        "            # if (batch_idx) % 20 == 0:\n",
        "            #     print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' .format(epoch, n_epochs, batch_idx, total_step, loss.item()))\n",
        "        ### end of for ... in tepoch ###\n",
        "\n",
        "        train_acc.append(100 * correct / total)\n",
        "        train_loss.append(running_loss/total_step)\n",
        "        print(f'Epoch {epoch}: train loss = {np.mean(train_loss):.4f}, train acc = {(100 * correct / total):.4f}')\n",
        "\n",
        "        # validation and saving\n",
        "        time.sleep(0.5)\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            with tqdm(validation_loader, unit=\"batch\") as tepoch:\n",
        "                batch_loss = 0\n",
        "                total_t=0\n",
        "                correct_t=0\n",
        "                for data_t, target_t in tepoch:\n",
        "                    tepoch.set_description(f\"Epoch {epoch}\")\n",
        "                    if device != \"cpu\": data_t, target_t = data_t.to(device), target_t.to(device) # on GPU\n",
        "                    outputs_t = model(data_t)\n",
        "                    _, pred_t = torch.max(outputs_t, dim=1)\n",
        "                    loss_t = criterion(outputs_t, target_t)\n",
        "                    #---\n",
        "                    loss_t_now = loss_t.item()\n",
        "                    correct_t_now = (pred_t == target_t).sum().item()\n",
        "                    accuracy_t_now = correct_t_now / batch_size\n",
        "                    #---\n",
        "                    batch_loss += loss_t_now\n",
        "                    correct_t += torch.sum(pred_t==target_t).item()\n",
        "                    total_t += target_t.size(0)\n",
        "                    #---\n",
        "                    tepoch.set_postfix(loss = loss_t_now, accuracy =100. * accuracy_t_now, position = epoch - 1) #; time.sleep(0.1)\n",
        "                ### end of for ... in tepoch ###\n",
        "                val_acc.append(100 * correct_t / total_t)\n",
        "                val_loss.append(batch_loss/len(validation_loader))\n",
        "                network_learned = batch_loss < valid_loss_min\n",
        "                print(f'Epoch {epoch}: val. loss = {np.mean(val_loss):.4f}, val. acc = {(100 * correct_t / total_t):.4f}')\n",
        "\n",
        "                # Saving the best weight\n",
        "                Cell_info[\"time\"], Cell_info[\"epoch_past\"] = nowDatetime, epoch\n",
        "\n",
        "                if SAVE == True:\n",
        "                    if network_learned:\n",
        "                        valid_loss_min = batch_loss\n",
        "                        Cell_info[\"best val.acc\"], Cell_info[\"best epoch\"], Cell_info[\"best val.loss\"]= round(100 * correct_t / total_t, 4), epoch, round(valid_loss_min, 4)\n",
        "                        # save model\n",
        "                        torch.save(model.state_dict(), saving_dir + \"/\" + NAME + \".pt\" )\n",
        "                        # save Epoch in .txt\n",
        "                        f = open(TXT_PATH, 'a'); f.write(\"Epoch \" + str(epoch) + \"\\n\") ; f.close()\n",
        "                        # save Cell_info in .json\n",
        "                        a_file = open(DICT_PATH_now, \"w\"); json.dump(Cell_info, a_file); a_file.close()\n",
        "                        print('Improved - SAVE the current model')\n",
        "                    else:\n",
        "                        print('Not improved')\n",
        "                else:\n",
        "                    if network_learned:\n",
        "                        valid_loss_min = batch_loss\n",
        "                        Cell_info[\"best val.acc\"], Cell_info[\"best epoch\"], Cell_info[\"best val.loss\"]= round(100 * correct_t / total_t, 4), epoch, round(valid_loss_min, 4)\n",
        "                        print('Improved - NOT save the model, just check')\n",
        "                    else:\n",
        "                        print('Not improved')\n",
        "        \n",
        "                print(Cell_info, \"\\n\", \"-----\"*15)\n",
        "                #---\n",
        "                model.train()\n",
        "                time.sleep(0.3)\n",
        "            ### end of <validation> with tqdm ...\n",
        "        ### end of <validation> with torch.no_grad()\n",
        "    ### end of <training> with tqdm ...\n",
        "### end of <training> for epoch in range(1, n_epochs+1)\n",
        "f = open(TXT_PATH, 'a')\n",
        "f.write(\"-----\\n\")\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpMYha1HKZn8"
      },
      "source": [
        "Load model to test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CPM3DUBEJgT"
      },
      "source": [
        "##### LOAD the best model #####\n",
        "if LOAD == True:\n",
        "    if device == \"cpu\":\n",
        "        MODEL = TypicalCNN() \n",
        "    else:\n",
        "        MODEL = TypicalCNN().to(device)\n",
        "    #---\n",
        "    if LOAD_now == True:\n",
        "        LOAD_loc = saving_dir + \"/\" + NAME + \".pt\"\n",
        "        print(\"nowDatetime\", nowDatetime)\n",
        "    else:\n",
        "        LOAD_loc = result_dir + \"/classify/\" + TIMESTAMP + \"/\" + NAME + \".pt\"\n",
        "        print(\"TIMESTAMP\", TIMESTAMP)\n",
        "    #---\n",
        "    #MODEL.load_state_dict(torch.load(LOAD_loc)) # load GPU model to GPU\n",
        "    MODEL.load_state_dict(torch.load(LOAD_loc, map_location=device)) # load GPU model to CPU model\n",
        "else:\n",
        "    MODEL = model\n",
        "#---\n",
        "MODEL.eval()\n",
        "print(device, \"\\n\", LOAD_loc, \"\\n----------\")\n",
        "print(MODEL)\n",
        "model_dict[\"TypicalCNN\"] = MODEL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJY1KBjFKYW9"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glWGATjWfMK4"
      },
      "source": [
        "##### Test #####\n",
        "label_num = 6000\n",
        "label_correct = list(0. for i in range(label_num))\n",
        "label_total = list(0. for i in range(label_num))\n",
        "correct_t = 0\n",
        "#---\n",
        "time.sleep(0.5)\n",
        "with torch.no_grad():\n",
        "    MODEL.eval()\n",
        "    with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
        "        for data_t, target_t in tepoch:\n",
        "            tepoch.set_description(f\"Test: \")\n",
        "            if device != \"cpu\": data_t, target_t = data_t.to(device), target_t.to(device) # on GPU\n",
        "            outputs_t = MODEL(data_t)\n",
        "            _, pred_t = torch.max(outputs_t, dim=1)\n",
        "            c_t = (pred_t == target_t).squeeze()\n",
        "            correct_t_now = (pred_t == target_t).sum().item()\n",
        "            accuracy_t_now = correct_t_now / batch_size\n",
        "            # correct_t += torch.sum(pred_t==target_t).item()\n",
        "            correct_t += correct_t_now\n",
        "            # total_t += target_t.size(0)\n",
        "            for i in range(target_t.size(0)):\n",
        "                trgt = target_t[i]\n",
        "                label_correct[trgt] += c_t[i].item()\n",
        "                label_total[trgt] += 1\n",
        "            #---\n",
        "            tepoch.set_postfix(batch_accuracy =100. * accuracy_t_now, position = 0) #; time.sleep(0.1)\n",
        "            time.sleep(0.5)\n",
        "#---                \n",
        "# for i in range(batchsize):\n",
        "#     print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "# a = sum(label_total); b = len(test_loader) * batch_size\n",
        "# print(\"correct:\", a, \"/\", b, \"=\", a/b*100)\n",
        "# plt.plot(range(0, label_num), label_total)\n",
        "print(correct_t, \"/\", sum(label_total),  \"=\", 100 * correct_t / sum(label_total), \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJfkM68UHVWr"
      },
      "source": [
        "print(correct_t, \"/\", sum(label_total),  \"=\", 100 * correct_t / sum(label_total), \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}